# üêç Snake Agent

Welcome to my **Snake Agent** project! This project explores how a neural network can learn to play the classic game of **Snake**, with the end goal of implementing both a **software-based AI agent** and a **hardware-based FPGA implementation**.

## üéØ Project Goals

- Implement a Deep Q-Network (DQN) to learn how to play Snake using reinforcement learning in Python.
- Visualize the learning process and game performance over time.
- Translate the trained neural network into a **hardware-friendly format** and implement it in **Verilog** on an FPGA (e.g., Basys3).
- Build a **fully autonomous Snake-playing system** that runs independently on FPGA hardware.

## üß† AI Overview

This project uses a **Deep Q-Network (DQN)**:
- **State representation**: Encodes the game state (e.g., direction, food position, tail danger).
- **Action space**: [Straight, Turn Left, Turn Right].
- **Reward structure**: Positive reward for eating food, negative for dying, small penalty per time step to encourage efficiency.
- **Learning framework**: 
  - Experience replay
  - Epsilon-greedy exploration
  - Neural network for Q-value approximation

The training is done in Python using frameworks such as **PyTorch** or **TensorFlow**. In this project, I will use PyTorch due to it being easy to pick up.

## üïπÔ∏è Game Environment

The Snake game is implemented in Python using **Pygame**. The AI agent interacts with the environment by:
- Observing the current state of the game.
- Choosing an action based on its learned Q-values.
- Receiving rewards and updating its policy.


